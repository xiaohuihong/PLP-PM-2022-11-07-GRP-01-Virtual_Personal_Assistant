{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e314a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import json, re, unicodedata, string, typing, time\n",
    "import torch.nn.functional as F\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from nltk import word_tokenize\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0efd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data:  442\n",
      "Data Keys:  dict_keys(['title', 'paragraphs'])\n",
      "Title:  University_of_Notre_Dame\n",
      "Length of data:  48\n",
      "Data Keys:  dict_keys(['title', 'paragraphs'])\n",
      "Title:  Super_Bowl_50\n",
      "Train list len:  87599\n",
      "Test list len:  34726\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>[515, 541]</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>[188, 213]</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>[279, 296]</td>\n",
       "      <td>the Main Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>[381, 420]</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>[92, 126]</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  5733be284776f41900661182   \n",
       "1  5733be284776f4190066117f   \n",
       "2  5733be284776f41900661180   \n",
       "3  5733be284776f41900661181   \n",
       "4  5733be284776f4190066117e   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question       label  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...  [515, 541]   \n",
       "1  What is in front of the Notre Dame Main Building?  [188, 213]   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...  [279, 296]   \n",
       "3                  What is the Grotto at Notre Dame?  [381, 420]   \n",
       "4  What sits on top of the Main Building at Notre...   [92, 126]   \n",
       "\n",
       "                                    answer  \n",
       "0               Saint Bernadette Soubirous  \n",
       "1                a copper statue of Christ  \n",
       "2                        the Main Building  \n",
       "3  a Marian place of prayer and reflection  \n",
       "4       a golden statue of the Virgin Mary  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset json files\n",
    "\n",
    "train_data = load_json('./dataset/squad_train.json')\n",
    "test_data = load_json('./dataset/squad_test.json')\n",
    "\n",
    "# parse the json structure to return the data as a list of dictionaries\n",
    "\n",
    "train_list = parse_data(train_data)\n",
    "test_list = parse_data(test_data)\n",
    "\n",
    "print('Train list len: ',len(train_list))\n",
    "print('Test list len: ',len(test_list))\n",
    "\n",
    "# converting the lists into dataframes\n",
    "\n",
    "train_df = pd.DataFrame(train_list)\n",
    "test_df = pd.DataFrame(test_list)\n",
    "\n",
    "def normalize_spaces(text):\n",
    "    '''\n",
    "    Removes extra white spaces from the context.\n",
    "    '''\n",
    "    text = re.sub(r'\\s', ' ', text)\n",
    "    return text\n",
    "\n",
    "train_df.context = train_df.context.apply(normalize_spaces)\n",
    "test_df.context = test_df.context.apply(normalize_spaces)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0805eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices of outliers and drop them from the dataframe\n",
    "\n",
    "drop_ids_train = filter_large_examples(train_df)\n",
    "train_df.drop(list(drop_ids_train), inplace=True)\n",
    "\n",
    "drop_ids_test = filter_large_examples(test_df)\n",
    "test_df.drop(list(drop_ids_test), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c29bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87335, 34439)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51c54b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in dataset:  118441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " \"As at most other universities, Notre Dame's students run a number of news media outlets. The nine student-run outlets include three newspapers, both a radio and television station, and several magazines and journals. Begun as a one-page journal in September 1876, the Scholastic magazine is issued twice monthly and claims to be the oldest continuous collegiate publication in the United States. The other magazine, The Juggler, is released twice a year and focuses on student literature and artwork. The Dome yearbook is published annually. The newspapers have varying publication interests, with The Observer published daily and mainly reporting university and other news, and staffed by students from both Notre Dame and Saint Mary's College. Unlike Scholastic and The Dome, The Observer is an independent publication and does not have a faculty advisor or any editorial oversight from the University. In 1987, when some students believed that The Observer began to show a conservative bias, a liberal newspaper, Common Sense was published. Likewise, in 2003, when other students believed that the paper showed a liberal bias, the conservative paper Irish Rover went into production. Neither paper is published as often as The Observer; however, all three are distributed to all students. Finally, in Spring 2008 an undergraduate journal for political science research, Beyond Politics, made its debut.\",\n",
       " 'The university is the major seat of the Congregation of Holy Cross (albeit not its official headquarters, which are in Rome). Its main seminary, Moreau Seminary, is located on the campus across St. Joseph lake from the Main Building. Old College, the oldest building on campus and located near the shore of St. Mary lake, houses undergraduate seminarians. Retired priests and brothers reside in Fatima House (a former retreat center), Holy Cross House, as well as Columba Hall near the Grotto. The university through the Moreau Seminary has ties to theologian Frederick Buechner. While not Catholic, Buechner has praised writers from Notre Dame and Moreau Seminary created a Buechner Prize for Preaching.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather text to build vocabularies\n",
    "\n",
    "vocab_text = gather_text_for_vocab([train_df, test_df])\n",
    "print(\"Number of sentences in dataset: \", len(vocab_text))\n",
    "vocab_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f907283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------word vocabulary-------------------\n",
      "raw-vocab: 110472\n",
      "vocab-length: 110474\n",
      "word2idx-length: 110474\n",
      "------------character vocabulary-----------------\n",
      "raw-char-vocab: 1397\n",
      "char-vocab-intersect: 230\n",
      "char2idx-length: 232\n"
     ]
    }
   ],
   "source": [
    "# build word and character-level vocabularies\n",
    "print(\"---------------word vocabulary-------------------\")\n",
    "word2idx, idx2word, word_vocab = build_word_vocab(vocab_text)\n",
    "print(\"------------character vocabulary-----------------\")\n",
    "char2idx, char_vocab = build_char_vocab(vocab_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "589fb498",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./dataset/qa_word2idx.npy',word2idx)\n",
    "np.save('./dataset/qa_idx2word.npy',idx2word)\n",
    "np.save('./dataset/qa_word_vocab.npy',word_vocab)\n",
    "np.save('./dataset/qa_char2idx.npy',char2idx)\n",
    "np.save('./dataset/qa_char_vocab.npy',char_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e2d7148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numericalize context and questions for training and testing set\n",
    "\n",
    "\n",
    "train_df['context_ids'] = train_df.context.apply(context_to_ids, word2idx=word2idx)\n",
    "test_df['context_ids'] = test_df.context.apply(context_to_ids, word2idx=word2idx)\n",
    "\n",
    "train_df['question_ids'] = train_df.question.apply(question_to_ids,  word2idx=word2idx)\n",
    "test_df['question_ids'] = test_df.question.apply(question_to_ids,  word2idx=word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4469b3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of error indices: 1000\n",
      "Number of error indices: 428\n"
     ]
    }
   ],
   "source": [
    "# get indices with tokenization errors and drop those indices \n",
    "\n",
    "train_err = get_error_indices(train_df, idx2word)\n",
    "test_err = get_error_indices(test_df, idx2word)\n",
    "\n",
    "train_df.drop(train_err, inplace=True)\n",
    "test_df.drop(test_err, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d0651d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get start and end positions of answers from the context\n",
    "# this is basically the label for training QA models\n",
    "\n",
    "train_label_idx = train_df.apply(index_answer, axis=1, idx2word=idx2word)\n",
    "test_label_idx = test_df.apply(index_answer, axis=1, idx2word=idx2word)\n",
    "\n",
    "train_df['label_idx'] = train_label_idx\n",
    "test_df['label_idx'] = test_label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c48fe98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump data to pickle files\n",
    "import pickle\n",
    "with open('./dataset/qaw2id.pickle','wb') as handle:\n",
    "    pickle.dump(word2idx, handle)\n",
    "\n",
    "with open('./dataset/qac2id.pickle','wb') as handle:\n",
    "    pickle.dump(char2idx, handle)\n",
    "    \n",
    "train_df.to_pickle('./dataset/qatrain.pkl')\n",
    "test_df.to_pickle('./dataset/qatest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79a8de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glove_matrix():\n",
    "    '''\n",
    "    Parses the glove word vectors text file and returns a dictionary with the words as\n",
    "    keys and their respective pretrained word vectors as values.\n",
    "\n",
    "    '''\n",
    "    glove_dict = {}\n",
    "    with open(\"./dataset/glove.840B.300d.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split(' ')\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype=\"float32\")\n",
    "            glove_dict[word] = vector\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    return glove_dict\n",
    "glove_dict = create_glove_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9df38f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_embedding(glove_dict):\n",
    "    '''\n",
    "    Creates a weight matrix of the words that are common in the GloVe vocab and\n",
    "    the dataset's vocab. Initializes OOV words with a zero vector.\n",
    "    '''\n",
    "    weights_matrix = np.zeros((len(word_vocab), 300))\n",
    "    words_found = 0\n",
    "    for i, word in enumerate(word_vocab):\n",
    "        try:\n",
    "            weights_matrix[i] = glove_dict[word]\n",
    "            words_found += 1\n",
    "        except:\n",
    "            pass\n",
    "    return weights_matrix, words_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f23980fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words found in glove vocab:  91193\n"
     ]
    }
   ],
   "source": [
    "weights_matrix, words_found = create_word_embedding(glove_dict)\n",
    "print(\"Total words found in glove vocab: \", words_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6ca1564",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./dataset/qaglove_vt.npy',weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b77e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
